{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "593b461e-3b64-4289-9e76-3f40647ffc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e01e98ad-f76f-4777-a4d2-7a0a7af01a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         buy       0.69      0.69      0.69       212\n",
      "        hold       0.64      0.68      0.66       270\n",
      "        sell       0.77      0.67      0.72       162\n",
      "\n",
      "    accuracy                           0.68       644\n",
      "   macro avg       0.70      0.68      0.69       644\n",
      "weighted avg       0.69      0.68      0.68       644\n",
      "\n",
      "Recommendation: hold\n",
      "Confidence: 0.79\n",
      "\n",
      "Feature Importance:\n",
      "      feature  importance\n",
      "6  Volatility    0.135891\n",
      "1      SMA_50    0.131752\n",
      "5      BB_low    0.128209\n",
      "4     BB_high    0.128030\n",
      "0      SMA_20    0.125910\n",
      "3        MACD    0.120908\n",
      "7    Momentum    0.118293\n",
      "2         RSI    0.111008\n",
      "\n",
      "Model saved as 'stock_prediction_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def fetch_stock_data(ticker, start_date, end_date):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    df = stock.history(start=start_date, end=end_date)\n",
    "    return df\n",
    "\n",
    "def calculate_rsi(prices, window=14):\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "def calculate_macd(prices, slow=26, fast=12, signal=9):\n",
    "    exp1 = prices.ewm(span=fast, adjust=False).mean()\n",
    "    exp2 = prices.ewm(span=slow, adjust=False).mean()\n",
    "    macd = exp1 - exp2\n",
    "    signal_line = macd.ewm(span=signal, adjust=False).mean()\n",
    "    return macd - signal_line\n",
    "\n",
    "def calculate_bollinger_bands(prices, window=20, num_std=2):\n",
    "    rolling_mean = prices.rolling(window=window).mean()\n",
    "    rolling_std = prices.rolling(window=window).std()\n",
    "    upper_band = rolling_mean + (rolling_std * num_std)\n",
    "    lower_band = rolling_mean - (rolling_std * num_std)\n",
    "    return upper_band, lower_band\n",
    "\n",
    "def create_features(df):\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    df['RSI'] = calculate_rsi(df['Close'])\n",
    "    df['MACD'] = calculate_macd(df['Close'])\n",
    "    df['BB_high'], df['BB_low'] = calculate_bollinger_bands(df['Close'])\n",
    "    df['Volatility'] = df['Close'].pct_change().rolling(window=20).std()\n",
    "    df['Momentum'] = df['Close'].pct_change(periods=10)\n",
    "    return df\n",
    "\n",
    "def create_labels(df, future_days=5, threshold=0.02):\n",
    "    df['Future_Return'] = df['Close'].pct_change(periods=future_days).shift(-future_days)\n",
    "    df['Label'] = np.where(df['Future_Return'] > threshold, 'buy',\n",
    "                           np.where(df['Future_Return'] < -threshold, 'sell', 'hold'))\n",
    "    return df\n",
    "\n",
    "def get_recommendation(model, latest_data, scaler):\n",
    "    scaled_data = scaler.transform(latest_data)\n",
    "    prediction = model.predict(scaled_data)[0]\n",
    "    confidence = np.max(model.predict_proba(scaled_data)[0])\n",
    "    return prediction, confidence\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Fetch data\n",
    "    ticker = 'AAPL'\n",
    "    start_date = '2010-01-01'\n",
    "    end_date = '2023-01-01'\n",
    "    df = fetch_stock_data(ticker, start_date, end_date)\n",
    "\n",
    "    # Prepare features and labels\n",
    "    df = create_features(df)\n",
    "    df = create_labels(df)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Prepare data for training\n",
    "    features = ['SMA_20', 'SMA_50', 'RSI', 'MACD', 'BB_high', 'BB_low', 'Volatility', 'Momentum']\n",
    "    X = df[features]\n",
    "    y = df['Label']\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define parameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Create a custom scorer that uses macro F1-score\n",
    "    f1_scorer = make_scorer(f1_score, average='macro')\n",
    "\n",
    "    # Perform GridSearchCV\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring=f1_scorer, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Example usage of get_recommendation\n",
    "    latest_data = X.iloc[-1:] # Get the most recent data point\n",
    "    recommendation, confidence = get_recommendation(best_model, latest_data, scaler)\n",
    "    print(f\"Recommendation: {recommendation}\")\n",
    "    print(f\"Confidence: {confidence:.2f}\")\n",
    "\n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({'feature': features, 'importance': best_model.feature_importances_})\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance)\n",
    "\n",
    "    # Save the model as a pickle file\n",
    "    with open('stock_prediction_model.pkl', 'wb') as file:\n",
    "        pickle.dump((best_model, scaler), file)\n",
    "    print(\"\\nModel saved as 'stock_prediction_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce976a-8d90-40c1-a8d2-af1832c8b864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
